<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
 
   
<!--  xhtml format, hw6 (tables) had to use transitional instead of strict dtd.  -->    
<!--
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">


the one below for strict html:
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

sttrict xhtml:

-->



<!--  
CSS Class - UCSCX - 2012.07 - Final Project 
Also making it as part of my PSG page remake.

CSS validator: http://jigsaw.w3.org/css-validator/#validate_by_uri
HTML validator: http://validator.w3.org/
-->    
    
<head>
	<title>Sys Admin Pocket Survival Guide - Amazon EC2</title>
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
        <link rel="stylesheet" href="psg2.css"                type="text/css" media="screen">
        <link rel="stylesheet" href="psg-table.css"           type="text/css">
        <link rel="stylesheet" href="psg2-links-icons.css"    type="text/css">
        <link rel="stylesheet" href="psg-positioning.css"     type="text/css">
        <link rel="stylesheet" href="psg-print.css" type="text/css" media="print">
</head>

    
<body>
  <!-- use hidden (HTML5) to get rid of the floater icons on upper right, they are just on the way! -->
  <div id="fixie"> <!-- add a fixed position example for css final project.   potentially use to place ad, which will appear like a 3rd column on right -->
          <div id="one"   class="skinny"><a href="plug/plug.html"><img src="plug/nema-5-20R-drawing.gif" alt="nema5pic" width="100" height="100"></a></div>
          <div hidden id="two"   class="skinny"><a href="fig/unixoid_hell.gif"><img src="fig/unixoid_hell.gif"  alt="vi-hell"   width="100" height="77" ></a></div>
          <div hidden id="three" class="skinny"><a href="fig/Assistant.gif"><img    src="fig/Assistant.gif"     alt="clippie"   width="100" height="77" ></a></div>
          <div hidden id="four"  class="skinny"><!-- empty for now --></div>
  </div> <!-- closes #fixie -->

    
<div id="wrapper">
  <div id="header">
    <div id="title">Sys Admin Pocket Survival Guide</div>
    <div id="sub-title">A Quick Reference Guide for Sys Admins with Alzeimer :)</div>
  </div> <!-- closes header -->
  
  <div id="navigation">
      <!-- the replace was not inside hightlight area, but whole page, finc and put back some strong and em in doc...-->
   <!--  strong, em, h5, or div are not allowed to be nested inside ul !!  -->
       <div class="azul">Unix</div>
	<ul>
        <li> <a href="sol.html">Solaris</a></li>
        <li> <a href="linux.html">Linux</a></li>
        <li> <a href="hpux.html">HP-UX</a> and <br>
                <a href="hpux.supl.html">supplement</a></li>
        <li> <a href="aix.html">AIX</a> and <br>
                <a href="aix_cd_catalog.html">AIX CD catalog</a><br></li>
        <li> <a href="irix.html">Irix</a></li>
        <li> <a href="dos.html">Windows</a></li>
        <li> <a href="apple.html">Apple Mac</a></li>
	</ul>

        <div class="azul">Storage</div>
	<ul>
        <li> <a href="netapp.html">NetApp</a></li>
        <li> <a href="emc.html">EMC SAN - Clariion</a></li>
        <li> <a href="emcCelerra.html">EMC NAS - Celerra</a></li>
        <li> <a href="isilon.html">Isilon</a></li>     
        <li> <a href="fs.html">Unix File System</a></li>
	</ul>

        <div class="azul">Big Data</div>
	<ul>
        <li> <a href="lsf.html">SGE/UGE, PBS/Torque, LSF.</a></li>
        <li> <a href="mpi.html">MPI, PVM</a></li>
        <li> <a href="sci-file.html">Science File Format/Info</a></li>
        <li><a href="sci-app.html">Sci-App</a></li>
        <li> <a href="bigdata.html">Big Data engines</a></li>
	</ul>
            
      
        <div class="azul">Unix Dev</div>
	<ul>
  	<li><a href="development.html">compilers, etc</a></li>
  	<li><a href="shellScript.txt">sh/bash, csh/tcsh</a></li>
  	<li><a href="awk.txt">AWK</a></li>
  	<li><a href="perl.html">Perl</a></li>
  	<li><a href="python.html">Python</a></li>
  	<li><a href="php.txt">PHP</a></li>
  	<li><a href="javascript_eg.html">javascript_eg</a></li>
   	<li>gcc</li>
  	<li><a href="gdb.html">gdb</a></li>
   	<li>java</li>
   	<li>rcs, cvs, p4, subversion</li>
	<li><a href="vi.html">vi</a></li> 
	</ul>

        <div class="azul">Network</div>
	<ul>
        <li> <a href="ipmi.html">IPMI</a></li>
        <li> <a href="ipv6.html">IPv6</a></li>
        <li> <a href="net.html">Network</a></li>
        <li> <a href="infiniband.html">InfiniBand</a><br></li>
        <li> <a href="acopia.html">Acopia</a></li>
	</ul>

        <div class="azul">Other</div>
	<ul>
        <li> <a href="softenv+modules.html">SoftEnv, Environment Modules</a></li>
        <li> <a href="puppet.html">Puppet</a></li>
        <li> <a href="cfengine.html">CfEngine</a></li>
        <li> <a href="factory_pw.html">factory password</a></li>
        <li> <a href="ldap.html">LDAP</a><BR></li>
        <li> <a href="admin.html">General Unix Sys Admin </a></li>
        <li> <a href="tool.html">Sys Admin tools and performance tuning</a></li>
        <li> <a href="vnc.html">VNC, X Emulation</a></li>
        <li> <a href="backup.html">Unix backup</a></li>
        <li> <a href="general_unix.html">Generic Unix Commands</a></li>
        <li> <a href="veritas.html">Veritas</a></li>
        <li> <a href="legato.html">Legato Networker</a></li>
        <li> <a href="mysql.html">MySQL</a></li>
        <li> <a href="html.txt">HTML tags</a></li>
        <li> <a href="wiki.html">WiKi tags</a></li>
        <li> <a href="3rdParty">3rd Party and Vendor Docs Cache</a></li>
	</ul>

        <div class="azul">IMHO</div>
	<ul>
        <li> <a href="monitor.html">Network monitoring tool review</a></li>
        <li> <a href="netArch.html">Network Architecture Approaches</a></li>
        <li> <a href="docPlatform.html">Documentation platform</a></li>
	</ul>

        <div class="azul">Prod Review</div>
	<ul>
        <li><a href="termSvr.html">Terminal (Serial Console) Servers</a></li>
        <li><a href="ent_prod.html">Enterprise Products</a></li>
        <li><a href=""></a></li>
        <li> &nbsp; </li>
	</ul>
            
	<div class="azul">More</div>
	<ul>
	<li><a href="psg1.html">Full TOC</A></li>
	</ul>

  </div> <!-- closes #navigation -->


  <!-- ########################################################## -->
  <!-- ########################################################## -->
  
  <div id="content">

      <p>



<div align="CENTER">
<A HREF="http://www.explainxkcd.com/wiki/index.php/1737"><IMG SRC="fig/xkcd_datacenter_scale.png" width="96%" alt="xkcd comic"></A>
</div>


<!--<H2><div class="azul">Amazon EC2</div></H2>-->
<H1>Amazon Web Services</H1>

Amazon Web Services.  The Cloud.  A real cloud. Not really just vapor anymore :)<p>
<br>
</p>


<H3>Terminology</H3>


<UL>
<li>AWS - Amazon Web Services </li>
<li>EC2 - Elastic Cloud Compute. ie. Virtual Machine </li>
<li>ECS - EC2 Container Service. Run docker containers using EC2 instances</li>
<li>EBS - Elastic Block Storage. ie. emulate hd for VM/EC2 instance. </li>
<LI>EFS - Elastic File System.   ie. NFSv4  access to files </li>
<li>S3  - Simple Storage Service.  Not virtualizaton of hard drive, but a web-centric way of storing files  </li>
<li>Spot Instance - auction style VM, maybe terminated at any time when price exceed agreed price </li>
<li> </li>
</UL>


<A HREF="https://cloud.google.com/free/docs/aws-azure-gcp-service-comparison">GCP vs AWS vs Azure Name Translation</A> Think Rosetta Stone of cloud provider :P
<BR>

<PRE>
</PRE>
<BR><BR>

<H3>AWS Setup</H3>

<PRE>
aws configure			# initial config with user credential, prefered region, etc
scp -pr .aws remotehost: 	# duplicate config to another admin client.  dir/file should not be world readable
setenv | grep AWS_		# about 5 env var, include AWS_SECRET_ACCESS_KEY... feel less secure than having the .aws/ config dir above.

</PRE>


<PRE class="code">
[default]
output = text
region = us-west-2

# example .aws/config   equiv ENV should set them.
</PRE>

<PRE class="code">
[default]
aws_access_key_id = AKamaiIker53rdStAlph
aws_secret_access_key = /LYSquieremuchoWanhWahnFAKE123xfake123Ti

# example .aws/credentials   equiv ENV should set them, but INSECURE.
# awscli v 1.2.9 (on ubuntu) can't recognize this separate file and content is stored in the same config file above.
# the secret_access_key is very important and should be kept very private!!  (so don't put in env var!)
# The AWS_ACCESS_KEY_ID can be obtained from Web Console.  but not the secret access key can only be retrieved when it was first generated.
# Use IAM instead of the root account.  Each user can have 2 key_id/secrete at a time.  
# one annoying thing is that they id cannot be named to help remember which computer have used the info for aws config
# they can be copied and used in multiple computers.  but the .aws dir must be in some safe place!!
# feel like the password protected ssh/pem files provides much better security, but cannot be used with the awscli :(
#
# env var name
# AWS_ACCESS_KEY_ID
# AWS_SECRET_ACCESS_KEY
</PRE>


<PRE>


aws configure --profile user2	# create additional profile (eg personal vs work)


complete -C $(which aws_completer) aws		# allows for TAB completion of aws sub commands


# install pip, can be done with windows cygwin's python
wget https://bootstrap.pypa.io/get-pip.py 
sudo python get-pip.py
pip --help

# install aws cli once pip is in place   (Anaconda on Windows comes with pip and can install this successfully)
sudo pip install awscli


sudo apt-get install awscli		# ubuntu, mint now have .deb for the python package


</PRE>



<H3>EC2 Commands</H3>

<PRE>

aws ec2 describe-regions --output=text
aws ec2 describe-subnets --output=table

aws --region us-west-2 --output=table ec2 describe-instances | egrep  '(Value|PrivateIp|\ Name)'

aws ec2 describe-instances |  egrep 'Instance|PublicDnsName|stop|terminate|running'
aws ec2 describe-instances |  egrep 'InstanceId|InstanceType|PublicDnsName|stop|terminate|running'

aws --region us-east-1 ec2 describe-subnets --query 'Subnets[*].[SubnetId,CidrBlock,AvailabilityZone,Tags[?Key==`Name`] | [0].Value]' --filters "Name=vpc-id,Values=vpc-abcd1234" "Name=tag-value,Values=\*HPC\*"

for region in $(aws ec2 describe-regions --query 'Regions[*].[RegionName]' --output text); do echo $region; aws ec2 import-key-pair --region $region --key-name tin6150 --public-key-material "$(cat $HOME/.ssh/id_rsa-aws.pub)" ; done

aws ec2 authorize-security-group-ingress --group-id sg-903004f8 --protocol tcp --port 22 --cidr 203.0.113.0/ 24

aws ec2 describe-security-groups 

aws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port 22 --cidr 203.0.113.0/24	# allow port 22 inbound traffic

aws ec2 create-tags --resources i-xxxxxxxx --tags Key=MyNAME,Value=MyInstance    # add a name tag to my instance



aws ec2 describe-instances	# list all instances and their info
aws ec2 describe-instances --instance-id i-30d27590 --output=table
aws ec2 stop-instances     --instance-id i-30d27590
aws ec2 start-instances    --instance-id i-30d27590



# finding interchangeable Architecture 
aws ec2 describe-instance-types --filters Name=processor-info.supported-architecture,Values=x86_64 --query "InstanceTypes[*].InstanceType" --output text
aws ec2 describe-instance-types --filters Name=processor-info.supported-architecture,Values=arm64  --query "InstanceTypes[*].InstanceType" --output text


aws ec2 describe-volumes		# list all storage volumes, some may not be attached!
aws ec2 describe-volumes --output=text	# wide format closer to web gui presentation

</PRE>

<H3>Finding instance info from within the VM</H3>
<PRE>

lspci		# like see something like
		# 00:03.0 Unassigned class [ff80]: XenSource, Inc. Xen Platform Device (rev 01)



ec2-metadata -i								# Return the instance id of the current VM (AWS Linux)
ec2metadata --instance-id						# ubuntu w/ cloud-utils
wget -q -O -   http://instance-data/latest/meta-data/instance-id	# 
wget -q -O - http://169.254.169.254/latest/meta-data/instance-id	# 169.254.169.254 is IANA local link addr when NO DHCP address is received.  


</PRE>

<H3>EC2 Pricing</H3>

<ol>
<li>size is best indicator of pricing, m4.xlarge and c4.xlarge are about the same price, with both being more expensive than *.large</li>
<li>VM instanced are categorized as T,M,C,G,R can be thought of Tiny, Moderate, CPU, GPU, RAM.  Tiny are cheaper than Moderage.  Note that R type start as large, so there are no "small" pricing for this category. </li>
<li>VM with lots of storage are of type I, D</li>
<li>the number after the category is generation number. eg m3.medium uses newer CPU than m1.medium and thus slightly more expensive </li>
<li>OS type matter (due to license?).  List below is in increasingly more expensive even if VM type remains the same (eg for m4.large, 2015.09, N.Virginia):  
    <ol>
    <li>Linux          (0.126/hr) [CentOS?  Amazon Linux? No OS license fee]</li>
    <li>RHEL           (0.186/hr = $134/mo)</li>
    <li>SLES           (0.226)</li>
    <li>Windows        (0.252)</li>
    <li>Win w/ SQL web (0.261)</li>
    <li>Win w/ SQL std (0.927)</li>
    <li>Win w/ SQL ent (about 2x of SQL std)</li>
    <li></li>
    </ol>
<li>Look at free software in Amazon Marketplace is a easy way to see prices for all different types of instances.  eg.  <A HREF="https://aws.amazon.com/marketplace/pp/B00N44P7L6/ref=dtl_recsim_B00EQE493U_B00N44P7L6_2">NCBI Blast AMI</A></li>
</ol>

<PRE>

c5a
c5ad - essentially same as C5a, but has nvme ephemeral instance storage (eg for use as swap, which need to be setup each time instance is powered on)

ragd.12xlarge - the "g" is for gravitron, arm-based architecture, AMI not interchangeable with x86.

some pricing info as of 2022.09 for some of the instance I was using:

c5a.16xlarge  is $2.46/hour      no ephemeral NVME 
c5ad.16xlarge is $2.75/hour      2 nvme ephemeral instance storage
r6gd.12xlarge is $2.76/hour      the "g" is for gravitron arm based 
r5ad.12xlarge is $3.14/hour      384G RAM 48 core.
r6id.12xlarge is $3.63/hour                
r6id.16xlarge is $4.84/hour

r5n.2xlarge	$0.596	8	64 GiB	EBS Only	Up to 25 Gigabit
t3a.2xlarge	$0.3008	8	32 GiB	EBS Only	Up to 5 Gigabit


API Name	Instance Memory		vCPUs	Instance Storage	Network Performance	Linux On Demand cost
r5ad.16xlarge	512.0 GiB	64 vCPUs	2400 GB (4 * 600 GB NVMe SSD)	12 Gigabit	$4.192000 hourly
m5ad.24xlarge	384.0 GiB	96 vCPUs	3600 GB (4 * 900 GB NVMe SSD)	20 Gigabit	$4.944000 hourly
r5ad.24xlarge	768.0 GiB	96 vCPUs	3600 GB (4 * 900 GB NVMe SSD)	20 Gigabit	$6.288000 hourly
m6id.32xlarge	512.0 GiB	128 vCPUs	7600 GB (4 * 1900 GB NVMe SSD)	50 Gigabit	$7.593600 hourly
r6id.32xlarge	1024.0 GiB	128 vCPUs	7600 GB (4 * 1900 GB NVMe SSD)	50 Gigabit	$9.676800 hourly
x2iedn.16xlarge	2048.0 GiB	64 vCPUs	1900 GB NVMe SSD		50 Gigabit	$13.338000 hourly
x2iedn.32xlarge	4096.0 GiB	128 vCPUs	3800 GB (2 * 1900 GB NVMe SSD)	100 Gigabit	$26.676000 hourly


  #instance_type = "t2.micro"   # $0.020/hr  1 vCPU  0.6G RAM
  #instance_type = "t2.small"   # $0.023/hr  1 vCPU  2G
  #instance_type = "t2.medium"  # $0.046     2 vCPU  4G                # tested work for us-west-2
  #instance_type = "t3.large"   # $0.083     2 vCPU  8G
  #instance_type = "t3.xlarge"   # $0.166     4 vCPU 16G
  #instance_type = t4g.2xlarge	$0.2688		8	32 GiB	EBS Only	Up to 5 Gigabit
  #instance_type = r5a.2xlarge	$0.452		8	64 GiB	EBS Only	Up to 10 Gigabit


  instance_type = "c5a.16xlarge"  # $2.464       64 vCPU 128G
  #~~instance_type = "c5ad.16xlarge"  # $2.75       64 vCPU 128G , 2 TB NVME Ephemeral instance storage (for swap)
  #~~instance_type = "c5ad.16xlarge"  # $2.75       64 vCPU 128G , 2 TB NVME Ephemeral instance storage (for swap)
  #-instance_type = "x2gd.2xlarge"  # $0.668        8 vCPU 128G  arm64

If just added EBS storage to volume, cannot change instance type, probably for 6 hours, while the disk config changes are synced in the AWS region or something.  (Would get "unexpected error", but figure multiple EBS storage changes had this restrictions).

</PRE>

Source and Ref: 
<A HREF="https://aws.amazon.com/ec2/pricing/on-demand/">EC2 On-Demand pricing </A> **With search** <BR>
<A HREF="https://aws.amazon.com/ec2/pricing/">EC2 price list</A> <BR>
<A HREF="https://www.cloudzero.com/blog/aws-instance-types">instance type guide</A> (By cloud zero, mediocre) <BR>




<BR><BR>

<H3>EC2 vs Google Compute Cloud pricing</H3>

<PRE>
Hard to do apple to apple comparison, especially if get into spot/preemptible instance prices.  Info from pre historic era (ie pre COVID-19)

AWS    bill in 1 sec increment, min 10 sec.
Google bill in 1 min increment, min 10 min.  automatic discount for sustained use (seesm to be 24%).

prices are barebone VM, additional charges apply for OS needing license cost, app license, etc.
comparison done on Nov 8, 2015.


       aws/google,     def disk size		aws inst name and price			google inst name + price

1 cpu, 1.0/0.6 GB RAM, 8/10 GB disk		t2.micro  $0.013/hr ($ 9.36/mo) 	f1-micro  $0.008/hr ($5.76/mo)
1 cpu, 2.0/1.7 GB RAM, 				t2.small  $0.026/hr ($18.72/mo)		f1-small  $0.027/hr

2 cpu, 8.0/7.5 GB RAM, 				m4.large   $0.126/hr ($  90/mo) 	n1-std-2  $0.100/hr ($  72/mo)
32cpu, 108/120 GB RAM,				c3.8xlarge $1.680/hr ($1209/mo)	  n1-std-32 $1.600/hr ($1152/mo)


Additional charges:

Google: $0.40 for each 10 GB persistent disk, per month, charged even when VM is running.
AWS:    $0.12 for each  1 GB persistent disk, per month, charged even when VM is running.

AWS has IOPS limitation for EBS disks.
No inboud/outbound data charges seen so far.  Not sure if S3 has such charges.  
VPN could be separate charges.

</PRE>

<BR><BR>

<H2>Storage for EC2</H2>

<OL>
<LI>EBS: Elastic block storage.  Think of this as the virtual hard drive used in VMware.  Storage attached to specific instance of EC2 (VM).  EBS storage does not automatically go away when an instance is terminated, and can be manually attached to another instance if required.  
$ 0.10 / GB / month

<LI>EFS: This provide NFSv4 support (v3?).  Thus, provide file access to multiple instance.   $ 0.30 / GB-month, calculated by GB/day, added for the month.

<LI>SoftNAS: AWS marketplace vendor providing high-performance cloud NAS, up to 20 TB.  NFS, CIFS, iSCSI.  HA when deploy 2 requisite instance.   Implemented on EBS, and need EC2 to host their software.   So cost can range from $ 0.01/hr to $ 5.28/hr + cost of EBS storage.

<LI>Glacier: for data backup and archiving, extremely low cost.  $ 0.007 / GB + cost of xfer out ( $ 0.09 / GB ) <BR>
    Store an .tar or .zip, immutable.  Each one assigned an archive ID.

<LI>S3: Simple Storage Service.  This is object store.  provides web interface to access a given object.  no file system interface provided.
<LI>
</OL>

<BR><BR>
<H3>EFS</H3>
Elastic File System - in Beta as of 2015.11 <BR>

<OL>
<LI>Secure access within VPC.
<LI>
<LI>
<LI>http://docs.aws.amazon.com/efs/latest/ug/whatisefs.html
</OL>


<H3>SoftNAS</H3>
<LI>SoftNAS: AWS marketplace vendor providing high-performance cloud NAS, up to 20 TB.  NFS, CIFS, iSCSI.  HA when deploy 2 requisite instance.   Implemented on EBS, and need EC2 to host their software.   So cost can range from $ 0.01/hr to $ 5.28/hr + cost of EBS storage.

<PRE>
</PRE>

<H3>Ephemeral storage</H3>

<OL>
<LI> *NOT Persistent!!*  Files saved will be gone after reboot of EC2 instance.
<LI> Physically attachable to EC2 instance, so does behave like a virtual hard disk.   Often mounted as /media/ephemeral0.  
<LI> It is free, but only comes with the larger instances, of increasing size.
<LI> better performance than EBS.
<LI> Ideal as the root drive of an HPC cluster node, where no storage is needed (AMI is copied to ephemeral disk on boot?).
<LI> Ephemeral storage is considered instance storage.  But to use this as boot device, need to do so before the host is created, by using a device mapping such as /dev/sdc=ephemeral0.  
</OL>

<H3>Direct-attached storage</H3>

<OL>
<LI>Not to be confused with physically-attached storage, which is what EBS is.
<LI>It is native to a specific EC2 instance.  Likely hard drive on the same physical server hosting the EC2 instance.  As such, it is not mountable to a different EC2 instance!
<LI>Not shared, so Potentially/Likely better performance than EBS, and less variance in performance.
<LI>Offered on beefier EC2 only.  Maybe more worthwhile to use than paying for PIOPS EBS.
<LI>There *is* SPOF in direct-attached storage.
<LI>Persistent data (should be, double check).
<LI>
</OL>


<H3>EBS</H3>

<OL>
<LI>EBS emulates a virtual hard drive, so it is mounted by a specific EC2 instance for use, but it lives independent of any given EC2 instance.  ie, it is NOT instance storage, and persist after an EC2 is terminated (deleted).
<LI>Only mountable in the same availability region.  But then it has no replication delay.
<LI>Has two tiers.  Standard IOPS, and Provisioned IOPS (PIOPS).  The latter allow extra payment to get dedicated performance.  It is not necessary faster, but will be more predictable (less variable, less likely to have bad performance because other instance is sharing the hardware and hitting it hard).
<LI> gp2 (general purpose ssd storage) = 0.10 per GB-month of provisioned storage - ie $102/TB-month
<LI> gp3 (general purpose ssd storage) = 0.08 per GB-month of provisioned storage - ie $ 82/TB-month + IOPS cost.  gp3 + 9000 IOPS = same perf but cheaper than gp2.  so use gp3!


</OL>

data volume management thoughts <BR>
attach volume to OS, no partition, create PV on whole virtual disk eg xvdf.  <BR>
expansion: create another volume in aws, attach to OS, eg xvdg, create PV, add to existing VG.  
shrink: can then do pvremove if extra partition not needed.   (cuz don't think shrinking aws gp3 ssd will properly ensure fs data block is not removed).
<BR>
each  gp3 vol has 3000 IOPS free.  using LVM can spread IO over multiple gp3 PV :) <BR>
(though IOPS aren't too expensive, extra volume in the list may be problematic for large cloud) <BR>



<H3>S3</H3>

<OL>
<LI>Web-centric way to access files.  Main use case is programmer coding app to access files/objects using AWS S3 API.
<LI>It does not emulate a virtual hard drive as EBS does.
<LI>Files in S3 is accessible from any AWS Region.  It also can be replicated for availability and performance.
<LI>Works on "eventually consistent" model.  Has replication delay.
</OL>
<H3>Glacier</H3>

<OL>
<LI>Glacier is like S3, much slower, and much cheaper.  but has an upload/download charge structure.
<LI>intended for archival.  may take hours for files to be fetched from (likely tape) before it is usable.
<LI>
<LI>
</OL>


<H1>Cloud "VM"</H1>


<!-- set tabstop=8
1-----------------------------------------------------------------------------80
12345678 2345678 2345678 2345678 2345678 2345678 2345678 2345678 2345678 2345678 -->
<PRE>
				aws		gcp		azure
				---------------	---------------	----------------
service name			ec2
def username			ec2-user
billing inc			1 sec
billing min			10 sec ?

</PRE>

<H1>Cloud Container</H1>

<!-- set tabstop=8
1-----------------------------------------------------------------------------80
12345678 2345678 2345678 2345678 2345678 2345678 2345678 2345678 2345678 2345678 -->
<PRE>

				aws		gcp		azure
				---------------	---------------	----------------
service name			eks
def username			
billing 



</PRE>
<H1>AWS Region</H1>

<PRE>
us-east-1 = Virginia     ###
us-east-2 = Ohio
us-west-1 = California
us-west-2 = Oregon       #

</PRE>

These resources are region specific:

<UL>
<LI>AMI-id.  ie, TF script that create EC2 instance must use ami-nnnnn from the same region, or get vague "resource unavailable" error.  Permission are also not copied when AMI is copied across region</LI>
<LI>EC2 key pair.  These ssh key to login to machine (needed during instance creation) are listed under EC2, not under user security.  </LI>
<LI>Security Groups.  But TF create them and will track them.</LI>
<LI>EC2 instance.  the i-nnnn is region specific.</LI>
<LI></LI>
</UL>

These are globally unique
<UL>
<LI>S3</LI>
<LI>IAM user</LI>
<LI></LI>
</UL>

<H1>Using S3 to serve static-content web site</H1>

S3 can be used to host a web site that does not need to serve server-side dynamic content.
It is well documented, see 
<A HREF="http://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html">overview</A> and 
<A HRER="http://docs.aws.amazon.com/AmazonS3/latest/dev/HowDoIWebsiteConfiguration.html">Bucket config</A>.
<BR>
Be forwarned that each little file retrieval add to the cost.  A web site may have very many little files, so this cost may add up! <BR>


<UL>
<LI>Create a bucket.  eg tin6150.
<LI>Use standard storage, not "infrequenst access storage" or "glacier storage", as acces surchage on the latter are expensive!
<LI>Upload files to the bucket, set upload details, permissions of "Make everything public".   This just means the file's properties will say Grantee: Everyone to open/download, but not edit.  View Permissions apparently is not needed.
<LI>Set bucket property to enable web hosting.  This will generate an website end point based on the region the bucket is, eg: <A HREF="http://tin6150.s3-website-us-west-1.amazonaws.com">http://tin6150.s3-website-us-west-1.amazonaws.com</A>
<LI>Upload will overwrite old files w/o warning.  it will set new permission as per latest upload.
<LI>
<LI><A HREF="https://aws.amazon.com/s3/pricing/">S3 Pricing details</A>
<LI>Storage cost isn't bad.
<LI>GET request are substantially cheaper than POST and PUT request
<LI>Upload to AWS (xfer IN) is free
<LI>xfer OUT (ie, visitor retrieving files to see the web site) has a per GB data xfer OUT fee.  This is in ADDITION to the GET or POST request fee.  Like the Hotel California song, you can check out but you can never leave! :-P
<LI>
<LI>Upload a folder works, no need to pre-create a folder.
<LI>
<LI>There are options to set a DNS domain to point to the S3 web site, see AWS Route 53 or even a DNS CNAME to the S3 endpoint, eg <A HREF="http://tiny.cc/TIN">tiny.cc/TIN</A>.
</UL>

<A ID="s3"></A>
<A ID="s3_cli"></A>
<A ID="s3_commands"></A>
<H5>S3 commands</H5>


<PRE>

# S3 buckets are accessible globally, so while hosted in a region, I/O commands can work w/o specifying any region.

aws s3 ls					# list buckets
aws s3 mb s3://sapsg				# make bucket (name has to be GLOBALLY unique)
aws s3 rb ...					# remove bucket 
aws s3 ls sn-s3-bucket-oregon-webhosting	# list content of bucket named "sn-s3-bucket-oregon-webhosting"		## cat@grumpy
aws s3 ls sn-s3-bucket-oregon-webhosting/fig/	# it is more like "ls -ld", add tailing / to see content inside a dir
aws s3 ls s3://sn-s3-bucket-oregon-webhosting	# prefixing bucket name with s3:// is req with older awscli

aws s3 ls s3://sapsg				# t6@g 
aws s3 ls s3://tin6150				# t6@g
aws s3 ls s3://ask-margo			# t6@g
aws s3 ls s3://nibr				# cat@grump

aws s3 sync . s3://tin6150  --acl public-read	# sync is like rsync, skip files already in destination
aws s3 sync . s3://sapsg    --acl public-read	# xfer-in is free, so okay to test upload to s3 like this :)

aws s3 sync conf     s3://nibr/conf   --acl public-read		# conf is name of a dir in this eg
aws s3 sync conf     s3://ask-margo   --acl public-read		# the dirname must be stated in the destination too, or all files in the script/* dir will be placed at one level higher!
aws s3 sync conf/    s3://nibr        --acl public-read		# whether / is added to explicity state src is a dir.  This was likely aws cli 1.0 behavior

aws s3 sync my_data_dir s3://bild-aq-tin6150-data/my_data_dir          # aws cli 2.0 need to specify a destination dir 
aws s3 sync my_data_dir s3://bild-aq-tin6150-data/two-folder/deep-ok/  # and s3 will automagically do the "mkdir -p" for any necessary folder path


aws s3 sync .   s3://tin6150     --acl public-read  --exclude ".git/*"  # exclude .git DB files
aws s3 cp   fig s3://tin6150/    --acl public-read  --recursive         # cp -R  fig folder copied and folder created in dest bucket

# note, it is possible to cp/sync between two s3 buckets

# remove all files in bucket before removing the bucket.  It cannot be renamed nor change region.
 aws s3 rm --recursive s3://old-junk
 aws s3 rb             s3://old-junk

</PRE>
<BR>
ref: <A HREF="http://docs.aws.amazon.com/cli/latest/userguide/using-s3-commands.html">S3 commands</A>
<BR>
<BR>

<H1>Security Stuff</H1>

ec2 key pair is the one that is related to ssh to ec2 instance, 
the key that is injected when an instance is spun up.
<BR>
In GUI, under EC2 section, should see "key pair" on the left navigation pane.
imported or create via GUI  (there maybe cli way to do this). 
<BR>
Anyway, EC2 key pairs can be listed by:

<PRE>
aws ec2 describe-key-pairs
aws ec2 describe-key-pairs --key-names tin@aws2208blactam.withPass

</PRE>


the ssh key maybe is for some code checking stuff (aws' git?)
so effing confusing!

when key is imported/created under <BR>
username, Security Credentials, AWS CodeCommit credentials.
It is NOT usable as EC2 key-pair to ssh in to an instance.
it shows up by:
<PRE>
aws iam list-ssh-public-keys
</PRE>


<H1>HPC in EC2</H1>


<A NAME="starcluster"></A>
<A NAME="StarCluster"></A>
<H2>MIT StarCluster</H2>

StarCluster from MIT provides an easy way to create (and terminate) an SGE cluster running on AWS EC2.  Characteristics:
<UL>
<LI> The AMI is based on Ubuntu 13.04 (as of 2015.12).   
<LI> Utilize Open Grid Scheduler (OGS, fork of SGE), Condor workload management.
<LI> Programming environment include, SciPy, NumPy, IPython, CUDA, PyCuda, PyOpenCL, OpenBLAS...
<LI> Provides OpenMPI, Hadoop,
<LI> A cluster-wide NFS mounted FS.  (An additional EBS volume need to be defined in the config, mounted by the master node)
<LI> 
<LI> IAM "EC2 Full Access" should be granted to the user that need to create nodes that form the starcluster.  ref: http://star.mit.edu/cluster/mlarchives/2112.html
<LI> 
<LI> 
</UL>

<H3>StarCluster setup</H3>

<PRE>

pip install starcluster
starcluster help
starcluster --region us-west-2 listpublic 	# list avail AMI
starcluster createkey -o ~/.ssh/mycluster.rsa  mycluseter
	# the public key is not returned by the above command
	# alt, can use -i option to import pre-generated ssh keys.
	# that key has to be imported into AWS IAM key pairs, or else get strange error about key does not exist in region us-east-1

# generate starcluster configfile, 
# edit ~/.starcluster/config with new key
# AWS info, NODE_IMAGE_ID with ami id in the desired region, NODE_INSTANCE_TYPE.

starcluster start -s 2 mycluster	# create and start a new cluster named "mycluster".  config read from ~/.startcluster/config
					# the default config, master node is also an sge exec host
					# they use a single NIC/IP, no distiction b/w private and public network.  
					# EC2 allocate a public IP for each node by default.

starcluster listclusters

starcluster restart    mycluster	# reboot all nodes.
starcluster terminate  mycluster	# terminate AMI, stop paying for it.  #EBS remains?
starcluster stop       mycluster	# only poweroff node, preserving EBS image (/mnt ephemeral storage will still be lost, of course!)
starcluster start -x   mycluster	# restart stopped cluster, all nodes will come back.


starcluster sshmaster  mycluster		# login to master node as root
starcluster sshmaster  mycluster -u sgeadmin	# login to master node as sgeadmin, can issue typical qconf commands from there.

</PRE>

<BR>
Info:
<OL>
<LI><A HREF="http://www.admin-magazine.com/HPC/Articles/StarCluster-Toolkit-Virtualization-Meets-HPC">Admin mag article</A>
<LI><A HREF="https://aws.amazon.com/customerapps/2824">AWS Marketplace page</A> 
<LI>
</OL>

<H2>AWS Batch</H2>

<UL>
<LI>AWS Batch is modeled after the HPC batch job running.  Perhaps more like HTC than HPC.  <BR>
<LI>No additional cost or special pricing, just need to pay for the EC2 instance needed to run the job.
<LI> Does not need to setup server to run the batch scheduler (so don't need to pay for an extra EC2 server to host such management (?))
<LI> Jobs that it run are docker container job.  So, maybe a kubernetes thing...
<LI> Batch has a manager to help bid for spot instances.
<LI> Could scale job wide for fewer hours rather than in-house HPC that is static size and run for days.
<LI> Resources are scaled up automatically to satisfy jobs, and scaled down when runnable jobs decreases.  One still have to manage min,desired,max vCPU.
<LI> ECS Agent is used to run containerized jobs.
<LI> 
</UL>

Ref: 
<UL>
<LI> <A HREF="https://aws.amazon.com/batch/faqs/">AWS Batch FAQ</A>
<LI> <A HREF="https://docs.aws.amazon.com/batch/latest/userguide/Batch_GetStarted.html">AWS Batch Getting Started</A>
<LI> 
</UL>

<H2>Virtualization Tech</H2>


<LI> paravirtual instances (PV) - historically the standard AMI virtualization.  Xen is used as the hypervisor.
<LI> hardware assisted virtual instances (HVM) - used in larger machines to circumvent hypervisor restrictions.  Increasingly used for all instances.
<LI> https://www.opswat.com/blog/aws-2015-why-you-need-switch-pv-hvm 


<H3>Performance</H3>

<PRE>
..
</PRE>

<H1>Database</H1>


Amazon RDS (Relational Database Service) offers a few database.  Notably Aurora, claimed to be MySQL compatible, but with improved performance, cache that lives thru db restart, etc.
For even aurora, DB sw still need to be setup by admin...  and so performance of DB is limited on the node instance that is running the DB.
<BR><BR>

DynamoDB is a NoSQL offering.  Fully managed, so just create tables and access data using API.  No need to maintain the DB itself, the DB is in some cloud, backed by distributed system.  Advertised as single digit ms latency at any scale.
<BR><BR>
Other eg of NoSQL DB includes: Hadoop, MongoDB.  <BR>
BigTable-based, rather than schema-less: Cassandra, HBase.
<BR><BR>

<H1>GCP - Google Cloud</H1>

<H2>GCP 101</H2>

<H3>ssh access</H3>
Easiest thing is to use the Web SSH on the VM detail page.  It does display this message:
<BR>
Please consider adding the IAP-secured Tunnel User IAM role (iap.tunnelInstances.accessViaIAP) to start using Cloud IAP for TCP forwarding for better performance.
<BR>

<H3>ssh keys - grumpy old sys admin way</H3>

It seems that ~/.ssh/authorized_keys is updated each time the Web SSH is activate.
When it says "copying ssh key to VM", that seems to be when it updates that.
It updates entry followed by (or after) <BR>
<TT># Added by Google</TT>
<BR>
so adding entries to the top of the authorized_keys 
don't seems to be wiped out.  <BR>
It still remains which user can login, other than the owner who created the instance...

<H3>ssh keys - google way</H3>

SSH keys are managed by the GCP environment.  
<BR>
~/.ssh/authorized_keys will be wiped when GCP need to push changes to the VM instance. <BR>
Keys in /etc/ssh/ should just be host keys. <BR>

Best is to 
<A HREF="https://cloud.google.com/compute/docs/oslogin/set-up-oslogin#gcloud">Enable OS Login</A>
<A HREF="https://cloud.google.com/compute/docs/instances/access-overview?hl=en">Choose an access method</A> (OS Login vs Managing SSH keys in metadata)
<OL>
(this seems to have been linked to some IAM , which might be pre-requisite)
<LI><A HREF="https://cloud.google.com/iam/docs/granting-changing-revoking-access#grant-single-role">Assign OS Login IAM roles - Project level</A>
<LI><A HREF="https://cloud.google.com/compute/docs/access/managing-access-to-resources#bind-member">Assign OS Login IAM roles - Instance level</A>
<LI>
</OL>
<BR>

2nd best is to manage metadata (GCP) and add individual key.
<A HREF="https://cloud.google.com/compute/docs/instances/access-overview?hl=en">Choose an access method</A> (See second section under "Managing SSH keys in metadata")
<A HREF="https://cloud.google.com/compute/docs/metadata/setting-custom-metadata#update_metadata">Updating metadata on a running VM</A>
ie.
for single VM instance.
edit the VM, ssh key should be listed and allow "add item".  
it is a tiny box to edit ssh key and some descriptive data.  it is a PITA.  eg, broke into several line for easier reading:
<PRE class="cf">
ecdsa-sha2-nistp256 
AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEbcqIe/lbynFItQAZpmwxr5mpecBeunOziOJgPiN18wEHx6jPZsS6ov+cjhpwiSxV6pMliZrfY3MgewtY5i6U0= 
google-ssh {
"userName":"tin@lbl.gov",
"expireOn":"2023-08-29T21:27:33+0000"
}
</PRE>
<PRE class="cf">
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCU6pjFRh+yAJ84AcKfD8xEUEyPzQoQhenPl47x9PL7bTOXK5qSdUyMtWk23T5AI+yFzdquWF8LyamH1qfFn2KKKIOeduSfgV+QmaBdIyjELbZ5SmxuiZ4k5PsXop9MxY65OULaJ1/LWXN4+/WURVvjTM0IrhtZayjpkarlItBvt/RxdBZSitI7STYLJCmCkQwJu5BRJM0fimxvAxFusER9JCwXZeVtiyJxne03+UP0vdy7K09ZQwbcS8nYWVQJuvMypAUsPECguDHgZnHmCbJ3O50Jt8LIjGbJJdId9j4UqOdqIwoofp5Fna1N1b3cbB8WF++w6/5RROO/VfEAngLt google-ssh {"userName":"tin@lbl.gov","expireOn":"2023-08-29T21:27:48+0000"}
</PRE>

Adding this manually, just plain id_ed25519.pub format, where hostname was slightly edited manually before, but w/o google formatting:
<PRE class="cf">
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIDmvqObMYMqJ0zuzxb60xjtZOObA8nZCrlvx1oR6p6+F tin@wombat_bangwu.clave
</PRE>

<BR>

Web console can launch an ssh session to an instance even without the "enable OS login" setup above.
The web console has user authenticated to GCP web site, and from there i guess add a user to the VM and pipe in some key via sshd config.
maybe easiest for user, but then have to use the web ssh client.  at least cut-n-paste works.

for better ssh integration, then do the "enable OS login" or "metadata" setup.

<H3>sudoers</H3>

Web ssh login seems to place the user in group "google-sudoers" automatically.  But something is managing /etc/group, and users added to that group get selectively cleaned out by some process.  

<H2>GCP Getting Started</H2>
Install gcloud toolkit - see 


<PRE>
gcloud compute instances list					# list all instances
gcloud compute instances describe atlas-tin2023  | less		# get metadata of instance

</PRE>


<H1>Terraform</H1>

I am not a huge fan of terraform, it doesn't provide enough abstraction to be platform independent.
The resulting .tf file is full of aws riddle (or gcp), as it is tied to the provider.
No simple swapping (as Ansible can do for much function of the OSes).
<BR><BR>

but here are some commands anyway. <BR>
example setup in github cloudseed4lbl

<PRE>
terraform init
terraform fmt		# format all .tf files (for indentation), in place, so consider backup before running this.
			# returned filenames are files that it changed.  none if no changes.

terraform validate
terraform plan
terraform apply		# this is DESTRUCTIVE.  re-apply ami-id to the instance, previous data is erased!  even security group seems recreated.
terraform destroy	# will terminate instance, remove any created security group.

# terraform has no way to restart an instance, nor to just stop or start it.
# use the aws cli tool for that

aws ec2 stop-instances --region us-east-2 --instance-ids i-0123456789abcdef


</PRE>

<H1>Reference, see also...</H1>

<UL>
<LI><A HREF="https://docs.aws.amazon.com/cli/latest/index.html">AWS CLI</A></LI>
<LI><A HREF="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html">AWS concepts</A></LI>
<LI>http://docs.aws.amazon.com/cli/latest/reference/ec2/describe-instances.html
<LI><A HREF="docker.html">Docker</A>, linux container</LI>
<LI><A HREF="puppet.html">puppet</A></LI>
<LI><A HREF="cfengine.html">cfengine</A></LI>

</UL>

<H1>Useful links</H1>


<UL>
<LI><A HREF="https://instances.vantage.sh/?min_memory=384&min_storage=100&region=us-east-2&selected=r5ad.12xlarge">
vantage.sh AWS EC2 pricing and instance comparison</A>
<LI> <A HREF="https://www.instance-pricing.com/provider=aws-ec2/instance=c5ad.16xlarge/">instance-pricing.com</A> useful, but not as friendly as vantage.sh above.

<LI>

</UL>


<H1>Random tidbits to be sorted</H1>

<PRE>

finding pricing info on ec2

aws pricing get-products --service-code AmazonEC2 --filters "Type=TERM_MATCH,Field=instanceType,Value=c5ad.16xlarge" "Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)" --region us-east-1 | jq -rc '.PriceList[]' | jq -r '[ .product.attributes.servicecode, .product.attributes.location, .product.attributes.instancesku?, .product.attributes.instanceType, .product.attributes.usagetype, .product.attributes.operatingSystem, .product.attributes.memory, .product.attributes.physicalProcessor, .product.attributes.processorArchitecture, .product.attributes.vcpu, .product.attributes.currentGeneration, .terms.OnDemand[].priceDimensions[].unit, .terms.OnDemand[].priceDimensions[].pricePerUnit.USD, .terms.OnDemand[].priceDimensions[].description] ' | less

</PRE>

<BR><BR>
<HR>
<BR><BR>

<A NAME="cc"></A>
<A NAME="CreativeCommon"></A>
<H3>Copyright info about this work
</H3>    

<p>
This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/">Creative Commons Attribution-NonCommercial-ShareAlike2.5 License</a>.
       <!--/Creative Commons License-->
       <!-- <rdf:RDF xmlns="http://web.resource.org/cc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
       <Work rdf:about="">
       <license rdf:resource="http://creativecommons.org/licenses/by-nc-sa/2.5/" />
            <dc:title>Pocket Sys Admin Survival Guide</dc:title>
            <dc:date>2005</dc:date>
            <dc:description>A series of concise system administration notes</dc:description>
            <dc:creator><Agent><dc:title>Tin Ho</dc:title></Agent></dc:creator>
            <dc:rights><Agent><dc:title>Tin Ho</dc:title></Agent></dc:rights>
            <dc:type rdf:resource="http://purl.org/dc/dcmitype/Text" />
            <dc:source rdf:resource="http://tin6150.github.io/psg/" />
            </Work>
            <License rdf:about="http://creativecommons.org/licenses/by-nc-sa/2.5/"><permits rdf:resource="http://web.resource.org/cc/Reproduction"/>
                                       <permits rdf:resource="http://web.resource.org/cc/Distribution"/>
                                       <requires rdf:resource="http://web.resource.org/cc/Notice"/><requires rdf:resource="http://web.resource.org/cc/Attribution"/>
                                       <prohibits rdf:resource="http://web.resource.org/cc/CommercialUse"/>
                                       <permits rdf:resource="http://web.resource.org/cc/DerivativeWorks"/><requires rdf:resource="http://web.resource.org/cc/ShareAlike"/>
            </License>
            </rdf:RDF> -->


<Strong>Pocket Sys Admin Survival Guide</Strong>: for content that I wrote, (<a
 href="http://creativecommons.org/licenses/by-nc-sa/2.5/">CC</a>)  
 <a href="http://creativecommons.org/learnmore"> <i>some rights reserved</i></a>.  
 2005,2012 Tin Ho [ tin6150 (at) gmail.com ]  <br>
 
Some contents are "cached" here for easy reference. Sources include man pages, 
vendor documents, online references, discussion groups, etc. Copyright of those 
are obviously those of the vendor and original authors.  I am merely caching them here for quick reference and avoid broken URL problems.
</p>

  <br><br>


<h3>Where is PSG hosted these days?</h3>
  <div id="psg-url">
  <a href="http://tiny.cc/EC2">tiny.cc/EC2</a><br>
  <a href="http://tin6150.github.io/psg/psg2.html">http://tin6150.github.io/psg/psg2.html</a> 
  This new home page at github<br>
  
  <A HREF="http://tiny.cc/tin6150"> 
  http://tiny.cc/tin6150/</A>
  New home in 2011.06.  <BR>



<A HREF="http://tin6150.s3-website-us-west-1.amazonaws.com/psg.html">http://tin6150.s3-website-us-west-1.amazonaws.com/psg.html</A> 
(coming soon)
<BR>
<a href="ftp://read:only@sn.is-a-geek.com/psg/psg.html">ftp://sn.is-a-geek.com/psg/psg.html</a> 
My home "server".  Up sporadically.
<BR>

<!--
Other caches in decreasing order of update frequency:  <BR>

<A HREF="http://tin6150.github.io/psg/psg.html">
http://tin6150.github.io/psg/psg.html
</A> 
(Google site, they are changing their policy and I may not be update these pages in the near future.  Last updated 2009-10-10)<BR>
-->


<A HREF="http://tin6150.github.io/psg/psg.html">http://tin6150.github.io/psg/psg.html</A> <BR>
<A HREF="http://www.fiu.edu/~tho01/psg/psg.html">http://www.fiu.edu/~tho01/psg/psg.html</A> (no longer updated as of 2007-05)<BR>

</div>       
      
      
      
      
      
      
      
      
      
      
      
      
  </div> <!-- #content -->
  
  
  <div id="tailer">      
            <div class="noicon">
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/2.5/">
                <img alt="Creative Commons License" src="http://creativecommons.org/images/public/somerights20.png"></a>
            <a href="http://jigsaw.w3.org/css-validator/check/referer">
                <img style="border:0;width:88px;height:31px"
                    src="http://jigsaw.w3.org/css-validator/images/vcss-blue"
                    alt="Valid CSS!">
            </a>
            <a href="http://validator.w3.org/check?uri=referer">
                <img src="http://www.w3.org/Icons/valid-html401" alt="Valid HTML 4.01 Strict" height="31" width="88">
            </a>
        </div>
  </div> <!-- #tailer -->

  
  
  
  
  <div id="footer"> (CC 2015-09) Some Rights Reserved.</div>
  
</div> <!-- closes wrapper --> 
</body>
<!-- vim: tabstop=8 
-->
</html>
